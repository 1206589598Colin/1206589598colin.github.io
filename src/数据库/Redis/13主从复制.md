
# 主从复制

## 是什么

主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，**Master写为主，****Slave****以读为主**

## 能干嘛

* 读写分离，性能扩展

* 容灾快速恢复

![](../../assets/images/2021-05-15-09-07-31.png)

## 怎么玩：主从复制

拷贝多个redis.conf文件include(写绝对路径)

开启daemonize yes

Pid文件名字pidfile

指定端口port

Log文件名字

dump.rdb名字dbfilename

Appendonly 关掉或者换名字

## 新建redis6379.conf，填写以下内容

```
include /myredis/redis.conf

pidfile /var/run/redis_6379.pid

port 6379

dbfilename dump6379.rdb
```

![](../../assets/images/2021-05-15-09-08-28.png)

### 新建redis6380.conf，填写以下内容

![](../../assets/images/2021-05-15-09-09-05.png)

### 新建redis6381.conf，填写以下内容

![](../../assets/images/2021-05-15-09-09-16.png)

slave-priority 10

设置从机的优先级，值越小，优先级越高，用于选举主机时使用。默认100

### 启动三台redis服务器

![](../../assets/images/2021-05-15-09-09-34.png)

### 查看系统进程，看看三台服务器是否启动

![](../../assets/images/2021-05-15-09-09-47.png)

### 查看三台主机运行情况

info replication

打印主从复制的相关信息

![](../../assets/images/2021-05-15-09-09-59.png)

### 配从(库)不配主(库)

```sh
slaveof  \<ip>\<port>
```

成为某个实例的从服务器

1、在6380和6381上执行: slaveof 127.0.0.1 6379

![](../../assets/images/2021-05-15-09-10-40.png)

2、在主机上写，在从机上可以读取数据

在从机上写数据报错

![](../../assets/images/2021-05-15-09-10-49.png)

3、主机挂掉，重启就行，一切如初

4、从机重启需重设：slaveof 127.0.0.1 6379

可以将配置增加到文件中。永久生效。

![](../../assets/images/2021-05-15-09-10-58.png)

## 常用3招

### 一主二仆

切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制?比如从k4进来，那之前的k1,k2,k3是否也可以复制？

从机是否可以写？set可否？ 

主机shutdown后情况如何？从机是上位还是原地待命？

主机又回来了后，主机新增记录，从机还能否顺利复制？ 

其中一台从机down后情况如何？依照原有它能跟上大部队吗？

![](../../assets/images/2021-05-15-09-11-36.png)

### 薪火相传

上一个Slave可以是下一个slave的Master，Slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master, 可以有效减轻master的写压力,去中心化降低风险。

用 slaveof  \<ip>\<port>

中途变更转向:会清除之前的数据，重新建立拷贝最新的

风险是一旦某个slave宕机，后面的slave都没法备份

主机挂了，从机还是从机，无法写数据了

![](../../assets/images/2021-05-15-09-11-52.png)

![](../../assets/images/2021-05-15-09-11-58.png)

### 反客为主

当一个master宕机后，后面的slave可以立刻升为master，其后面的slave不用做任何修改。

用 slaveof  no one  将从机变为主机。

![](../../assets/images/2021-05-15-09-12-12.png)

## 复制原理

* Slave启动成功连接到master后会发送一个sync命令

* Master接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令， 在后台进程执行完毕之后，master将传送整个数据文件到slave,以完成一次完全同步

* 全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。

* 增量复制：Master继续将新的所有收集到的修改命令依次传给slave,完成同步

* 但是只要是重新连接master,一次完全同步（全量复制)将被自动执行

![](../../assets/images/2021-05-15-09-12-36.png)

## 哨兵模式(sentinel)

### 是什么

**反客为主的自动版**，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库

![](../../assets/images/2021-05-15-09-13-09.png)

### 怎么玩(使用步骤)

#### 调整为一主二仆模式，6379带着6380、6381

![](../../assets/images/2021-05-15-09-13-38.png)

#### 自定义的/myredis目录下新建sentinel.conf文件，名字绝不能错

#### 14.6.2.3.配置哨兵,填写内容

sentinel monitor mymaster 127.0.0.1 6379 1

其中mymaster为监控对象起的服务器名称， 1 为至少有多少个哨兵同意迁移的数量。 

#### 启动哨兵

/usr/local/bin

redis做压测可以用自带的redis-benchmark工具

执行redis-sentinel  /myredis/sentinel.conf

![](../../assets/images/2021-05-15-09-15-40.png)

#### 当主机挂掉，从机选举中产生新的主机

(大概10秒左右可以看到哨兵窗口日志，切换了新的主机)

哪个从机会被选举为主机呢？根据优先级别：slave-priority 

原主机重启后会变为从机。

![](../../assets/images/2021-05-15-09-16-00.png)

#### 复制延时

由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。

#### 故障恢复

![](../../assets/images/2021-05-15-09-16-36.png) 

优先级在redis.conf中默认：slave-priority 100，值越小优先级越高

偏移量是指获得原主机数据最全的

每个redis实例启动后都会随机生成一个40位的runid

### 主从复制

```java
private static JedisSentinelPool jedisSentinelPool=null;

public static  Jedis getJedisFromSentinel(){
    if(jedisSentinelPool==null){
                Set\<String> sentinelSet=new HashSet\<>();
                sentinelSet.add("192.168.11.103:26379");

                JedisPoolConfig jedisPoolConfig =new JedisPoolConfig();
                jedisPoolConfig.setMaxTotal(10); //最大可用连接数
    jedisPoolConfig.setMaxIdle(5); //最大闲置连接数
    jedisPoolConfig.setMinIdle(5); //最小闲置连接数
    jedisPoolConfig.setBlockWhenExhausted(true); //连接耗尽是否等待
    jedisPoolConfig.setMaxWaitMillis(2000); //等待时间
    jedisPoolConfig.setTestOnBorrow(true); //取连接的时候进行一下测试 ping pong

    jedisSentinelPool=new JedisSentinelPool("mymaster",sentinelSet,jedisPoolConfig);
    return jedisSentinelPool.getResource();
            }else{
    return jedisSentinelPool.getResource();
    }
}
```